{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c4217e-04b5-4610-8ae9-ca2aa6a07b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved fold10.csv\n",
      "Processed and saved fold2.csv\n",
      "Processed and saved fold1.csv\n",
      "Processed and saved fold3.csv\n",
      "Processed and saved fold4.csv\n",
      "Processed and saved fold5.csv\n",
      "Processed and saved fold6.csv\n",
      "Processed and saved fold7.csv\n",
      "Processed and saved fold9.csv\n",
      "Processed and saved fold8.csv\n"
     ]
    }
   ],
   "source": [
    "######################################### Remove any occurance of \"Others\"  ############################\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_check_and_save_csv(input_folder, output_folder, column_name):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            input_file_path = os.path.join(input_folder, filename)\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(input_file_path)\n",
    "            # Check if the specified column exists in the dataframe\n",
    "            if column_name in df.columns:\n",
    "                # Filter out rows containing \"other\" or \"Other\" in the specified column\n",
    "                filtered_df = df[~df[column_name].str.contains('other', case=False, na=False)]\n",
    "                # Save the filtered dataframe to the output folder\n",
    "                output_file_path = os.path.join(output_folder, filename)\n",
    "                filtered_df.to_csv(output_file_path, index=False)\n",
    "                print(f\"Processed and saved {filename}\")\n",
    "            else:\n",
    "                print(f\"Column '{column_name}' not found in {filename}\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = 'Dataset/AdjuvareDB104_Standard/10_folds/'  # Replace with the path to your input folder\n",
    "output_folder = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/'  # Replace with the path to your output folder\n",
    "column_name = 'Adjuvant Name'    \n",
    "load_check_and_save_csv(input_folder, output_folder, column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92eb381b-0c5e-4147-8006-09bf6cba4a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCT Number: NCT00148928\n",
      "  Column: Study Title\n",
      "    Word: &, Special Characters: ['&']\n",
      "NCT Number: NCT02229084\n",
      "  Column: Interventions\n",
      "    Word: MONTANIDE™, Special Characters: ['™']\n",
      "NCT Number: NCT02364492\n",
      "  Column: Brief Summary\n",
      "    Word: µg,, Special Characters: ['µ']\n",
      "    Word: µg, Special Characters: ['µ']\n",
      "    Word: µg, Special Characters: ['µ']\n",
      "NCT Number: NCT00470574\n",
      "  Column: Interventions\n",
      "    Word: Lewisª-keyhole, Special Characters: ['ª']\n",
      "NCT Number: NCT00199901\n",
      "  Column: Study Title\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "  Column: Brief Summary\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "  Column: Interventions\n",
      "    Word: ISCOMATRIX®|BIOLOGICAL:, Special Characters: ['®']\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "  Column: Adjuvant Name\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "NCT Number: NCT00694551\n",
      "  Column: Brief Summary\n",
      "    Word: γ, Special Characters: ['γ']\n",
      "NCT Number: NCT00518206\n",
      "  Column: Study Title\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "  Column: Brief Summary\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "  Column: Interventions\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "  Column: Adjuvant Name\n",
      "    Word: ISCOMATRIX®, Special Characters: ['®']\n",
      "NCT Number: NCT00705835\n",
      "  Column: Brief Summary\n",
      "    Word: Alhydrogel®, Special Characters: ['®']\n",
      "  Column: Interventions\n",
      "    Word: Alhydrogel®, Special Characters: ['®']\n",
      "  Column: Adjuvant Name\n",
      "    Word: Alhydrogel®, Special Characters: ['®']\n",
      "NCT Number: NCT02721043\n",
      "  Column: Brief Summary\n",
      "    Word: (Hiltonol®,, Special Characters: ['®']\n",
      "NCT Number: NCT02151448\n",
      "  Column: Study Title\n",
      "    Word: αDC1, Special Characters: ['α']\n",
      "NCT Number: NCT00199836\n",
      "  Column: Study Title\n",
      "    Word: Montanide®, Special Characters: ['®']\n",
      "  Column: Interventions\n",
      "    Word: Montanide®, Special Characters: ['®']\n",
      "NCT Number: NCT02593227\n",
      "  Column: Brief Summary\n",
      "    Word: (FRα), Special Characters: ['α']\n",
      "  Column: Interventions\n",
      "    Word: FRα, Special Characters: ['α']\n",
      "    Word: FRα, Special Characters: ['α']\n",
      "NCT Number: NCT02938442\n",
      "  Column: Interventions\n",
      "    Word: MONTANIDE™, Special Characters: ['™']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def check_special_characters(folder_path, nct_column):\n",
    "    # Define a regex pattern for special characters (excluding common punctuation and spaces)\n",
    "    special_char_pattern = re.compile(r'[^a-zA-Z0-9\\s,.\\-\\'+*/=()|:_;\"]')\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Check if the NCT column exists in the dataframe\n",
    "            if nct_column in df.columns:\n",
    "                # Iterate over each row in the dataframe\n",
    "                for index, row in df.iterrows():\n",
    "                    special_chars_found = {}\n",
    "                    # Check each column in the row for special characters\n",
    "                    for col in df.columns:\n",
    "                        cell_value = str(row[col])\n",
    "                        words = cell_value.split()  # Split cell value into words\n",
    "                        for word in words:\n",
    "                            special_chars = special_char_pattern.findall(word)\n",
    "                            if special_chars:\n",
    "                                # Add the word and special characters to the dictionary\n",
    "                                if col not in special_chars_found:\n",
    "                                    special_chars_found[col] = []\n",
    "                                special_chars_found[col].append((word, special_chars))\n",
    "                    # If special characters are found, print them with the NCT Number\n",
    "                    if special_chars_found:\n",
    "                        nct_number = row[nct_column]\n",
    "                        print(f\"NCT Number: {nct_number}\")\n",
    "                        for col, items in special_chars_found.items():\n",
    "                            print(f\"  Column: {col}\")\n",
    "                            for word, chars in items:\n",
    "                                print(f\"    Word: {word}, Special Characters: {chars}\")\n",
    "            else:\n",
    "                print(f\"Column '{nct_column}' not found in {filename}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/'  # Replace with the path to your folder\n",
    "nct_column = 'NCT Number'           \n",
    "check_special_characters(folder_path, nct_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dab7f6c-b00a-437d-95d6-9d58bed34fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and saved fold10.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold10.csv\n",
      "Cleaned and saved fold2.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold2.csv\n",
      "Cleaned and saved fold1.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold1.csv\n",
      "Cleaned and saved fold3.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold3.csv\n",
      "Cleaned and saved fold4.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold4.csv\n",
      "Cleaned and saved fold5.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold5.csv\n",
      "Cleaned and saved fold6.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold6.csv\n",
      "Cleaned and saved fold7.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold7.csv\n",
      "Cleaned and saved fold9.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold9.csv\n",
      "Cleaned and saved fold8.csv to Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/fold8.csv\n"
     ]
    }
   ],
   "source": [
    "########################################## Remove ® and ™   #####################################################\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_and_save_files(folder_path, nct_column, save_folder):\n",
    "\n",
    "    # Ensure save directory exists, create if not\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Check if the NCT column exists in the dataframe\n",
    "            if nct_column in df.columns:\n",
    "                # Iterate over each row in the dataframe\n",
    "                for index, row in df.iterrows():\n",
    "                    # Check and clean each column in the row\n",
    "                    for col in df.columns:\n",
    "                        cell_value = str(row[col])\n",
    "                        # Remove ® and ™\n",
    "                        cleaned_value = cell_value.replace(\"®\", \"\").replace(\"™\", \"\")\n",
    "                        df.at[index, col] = cleaned_value\n",
    "\n",
    "                # Save the cleaned DataFrame to a new CSV file\n",
    "                save_path = os.path.join(save_folder, filename)\n",
    "                df.to_csv(save_path, index=False)\n",
    "                print(f\"Cleaned and saved {filename} to {save_path}\")\n",
    "            else:\n",
    "                print(f\"Column '{nct_column}' not found in {filename}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/'  # Replace with the path to your folder\n",
    "nct_column = 'NCT Number'          \n",
    "save_folder = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/'  # Specify where to save cleaned files\n",
    "\n",
    "clean_and_save_files(folder_path, nct_column, save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03387511-2369-487d-9804-1f4a0ab5df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCT Number: NCT00148928\n",
      "  Column: Study Title\n",
      "    Word: &, Special Characters: ['&']\n",
      "NCT Number: NCT02364492\n",
      "  Column: Brief Summary\n",
      "    Word: µg,, Special Characters: ['µ']\n",
      "    Word: µg, Special Characters: ['µ']\n",
      "    Word: µg, Special Characters: ['µ']\n",
      "NCT Number: NCT00470574\n",
      "  Column: Interventions\n",
      "    Word: Lewisª-keyhole, Special Characters: ['ª']\n",
      "NCT Number: NCT00694551\n",
      "  Column: Brief Summary\n",
      "    Word: γ, Special Characters: ['γ']\n",
      "NCT Number: NCT02151448\n",
      "  Column: Study Title\n",
      "    Word: αDC1, Special Characters: ['α']\n",
      "NCT Number: NCT02593227\n",
      "  Column: Brief Summary\n",
      "    Word: (FRα), Special Characters: ['α']\n",
      "  Column: Interventions\n",
      "    Word: FRα, Special Characters: ['α']\n",
      "    Word: FRα, Special Characters: ['α']\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed/'  # Replace with the path to your folder\n",
    "nct_column = 'NCT Number'       \n",
    "check_special_characters(folder_path, nct_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f957a96-c9c7-4b61-81f7-0008b077ca60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef7756-c1a4-4867-ba21-d4cdfe3a20e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f99a9a2-15e7-4b0c-96ab-8cf7a775f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "######################################## 10 folds with interventions merged columns ##################################\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the input and output directories\n",
    "input_dir = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed_with_intervention/'\n",
    "output_dir = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed_with_intervention_merged_columns/'\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to ensure each component ends with a period\n",
    "def ensure_period(s):\n",
    "    return s if s.endswith('.') else s + '.'\n",
    "\n",
    "# Process each file in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Load the CSV file\n",
    "        input_filepath = os.path.join(input_dir, filename)\n",
    "        df = pd.read_csv(input_filepath, sep=\"\\t\")\n",
    "        \n",
    "        # Create the merged column\n",
    "        df['Study Summary'] = ('Study Title: ' + df['Study Title'].apply(ensure_period) +\n",
    "                               ' Brief Summary: ' + df['Brief Summary'].apply(ensure_period) +\n",
    "                               ' Interventions: ' + df['Interventions'].apply(ensure_period))\n",
    "        \n",
    "        # Select only the necessary columns\n",
    "        df_output = df[['NCT Number', 'Study Summary']]\n",
    "        \n",
    "        # Save the modified DataFrame\n",
    "        output_filepath = os.path.join(output_dir, filename)\n",
    "        df_output.to_csv(output_filepath, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Files processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd178a4-85cc-4992-90e5-76863f11e5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "######################################## 10 folds without interventions merged columns ##################################\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the input and output directories\n",
    "input_dir = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed_without_intervention/'\n",
    "output_dir = 'Dataset/AdjuvareDB104_Standard/10_folds_preprocessed_without_intervention_merged_columns/'\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to ensure each component ends with a period\n",
    "def ensure_period(s):\n",
    "    return s if s.endswith('.') else s + '.'\n",
    "\n",
    "# Process each file in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Load the CSV file\n",
    "        input_filepath = os.path.join(input_dir, filename)\n",
    "        df = pd.read_csv(input_filepath, sep=\"\\t\")\n",
    "        \n",
    "        # Create the merged column\n",
    "        df['Study Summary'] = ('Study Title: ' + df['Study Title'].apply(ensure_period) +\n",
    "                               ' Brief Summary: ' + df['Brief Summary'].apply(ensure_period))\n",
    "        \n",
    "        # Select only the necessary columns\n",
    "        df_output = df[['NCT Number', 'Study Summary']]\n",
    "        \n",
    "        # Save the modified DataFrame\n",
    "        output_filepath = os.path.join(output_dir, filename)\n",
    "        df_output.to_csv(output_filepath, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Files processed and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52fceb-47be-4c09-83f9-fbad316f9730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaienv",
   "language": "python",
   "name": "openaienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
